---
title: Hadoop体系-HDFS
date: 2018-09-20 22:14:27
tags: [Big Data, Hadoop, HDFS]
categories: Hadoop
respository: git@github.com:Gfeather/feather.git
branch: master
---

*Data-driven production value*

## HDFS

*版本：HDFS1.0*

{% asset_img artic.png 简单分布式文件系统架构 %}


#### 需求

- 与单机FS相同或类似的用户(客户端)接口：能够通过shell、程序读写文件
- 多用户(客户端)读写：能够使处理多个读写请求
- 数据可靠性：能够处理数据出错、数据丢失等
- 集群可用性：能够在机器随时损坏的情况下，保证集群、数据可用
- 集群可伸缩性：能够随时增加、减少节点，同时数据相应伸缩

#### 体系结构

{% asset_img hdfs_detail.png %}

从名称节点的命名空间获得位置信息，从数据节点进行读写

> 名称节点：存储元数据信息，文件数、文件-数据块映射、数据块位置，核心`FsImage`、`EditLog`，`FsImage`用于维护文件树的所有元数据，`EditLog`记录了所有文件创建、删除、重命名等操作。名称节点会在启动时将`FsImage`载入内存，执行`EditLog`中的操作，期间处于**安全模式**：只允许对元数据的读操作，不允许写操作。
> 第二名称节点：作为名称节点的存档点提供元数据备份，定时将名称节点的`FsImage`、`EditLog`拉入本地，进行初始化。在这个期间名称节点会将新的操作写入`EditLog.new`中，第二名称节点初始化完成的`FsImage`替代旧的`FsImage`，`EditLog.new`替代`EditLog`。


- 命名空间管理：名称节点管理命名空间，包含目录、文件和块，负责它们的创建、复制和删除
- 通信协议：所有的HDFS通信协议都基于TCP/IP协议
> 客户端——名称节点：通过TCP建立连接，使用客户端协议交互
> 名称节点——数据节点：使用数据节点协议交互
> 数据节点——客户端：通过RPC(Remote Procedure Call)实现交互
	
*1.0局限*：
- 命名空间限制，名称节点能够存储的元数据有限，限制集群存储文件数量。
- 性能瓶颈，系统吞吐量被名称节点吞吐量限制。
- 隔离性，只有一个命名空间，所有应用都可以访问全部文件。
- 可用性，名称节点存在单点故障问题，secondarynode冷备无法热切换。



#### 存储原理

保证数据可靠性，使用多副本冗余、复制机制。副本数量一般为3(或指定更多)副本，系统会维持副本存活数量。

实现：
1，并行访问
2，多副本冗余检错
3，可靠性

- 存放策略：文件副本块分布，本机器一份，本机架其他机器一份，相邻机架一份，更多副本随机分配。块大小1.0为64M，2.0为128M，块大小由网络带宽和寻址间的关系决定，为了提高读取块的效率减少寻址时间和传输时间的占比。
- 读取策略：就近读取
- 复制策略：文件会在客户端切分成块，并逐块发送，数据节点根据发送的节点列表进行流水复制，数据写入和复制实现并行。
- 错误与恢复：
	- 名称节点出错：核心数据结构FsImage和EditLog失效则集群失效，由第二名称节点接替，同时从副本恢复
	- 数据节点出错，从副本恢复
	- 数据出错，校验码检错，从副本恢复
- 心跳机制：默认datanode每隔3s发送一次心跳机制，报告主机信息、块信息。当namenode连续10次没有收到心跳，隔300000ms(300s)后会发送确认信息，连续两次无回应则判断该节点宕机。
- 负载均衡：集群有自动负载均衡，在有限的带宽下。在配置中可以修改带宽限制，通过`start-balance.sh -t n% //n为最大和最小节点存储百分比的差值`，当达到指定限制后集群会在空闲时进行负载均衡。 

#### 数据读写

{% asset_img hdfs_r.png  %}

读：
1. 客户端通过`FileSystem.open()`打开文件，获得输入流`FSDataInputStream`，而对HDFS来说具体的输入流是`DFSInputStream`。
2. `DFSInputStream`的相应的get方法会获得存储某数据块的距离客户端最近的数据节点地址，`FileSystem`会使用它初始化`FSDataInputStream`。
3. 客户端使用`FSDataInputStream.read()`读取文件，当数据块读完之后，`DFSInputStream`会断开与数据节点的连接，获取下一个块，读取结束调用`FSDataInputStream.close()`。

综述：
1. 客户端通过RPC请求从namenode获取文件每一个块的节点列表
2. 客户端会就近读取数据块
3. 当前块读取完毕后关闭数据流，获取下一个块的节点列表，知道文件结束
4. 每次读取完毕都会进行checksum验证，如果出现错误，客户端会通知namenode，然后从下一个节点开始

{% asset_img hdfs_w.png  %}

写：
1. 客户端调用`FSDataOutputStream.write()`来向HDFS中的文件写入数据。
2. `FSDataOutputStream`中的数据会被分包存在`DFSOuputStream`的内部队列里，在发送时打成数据包发送，`FSDataOutputStream`向名称节点申请存放数据和副本的数据节点列表，然后这些节点进行流水复制。
3. 为了保证数据准确每个数据节点收到数据包后需要发送'确认包'(ACK),`ACK`会从数据节点管道往前发送直到客户端。
4. 如果写入期间发生故障，会关闭管线，把确认队列中所有的数据包都添加回数据队列最前端，保证不会漏掉任何一个数据包。为存储在正常datanode的当前数据块注册新的标识。从管线中删除故障datanode。构建新管线，余下的数据块写入正常datanode。namenode会维持副本数量到配置的副本数
4. 客户端调用`close()`方法后客户端不会写入数据，`DFSOuputStream`会在收到所有分包的`ACK`后通知名称节点关闭文件

综述：
1. 客户端通过RPC请求发出文件写入请求，namenode检验文件是否合法、用户权限后，创建记录，否则让客户端抛出异常
2. 客户端写入时将文件切分为数据包，用一个‘数据队列’来维护数据包信息，向namenode注册blocks并获得datanode列表
3. 创建管线，将blocks写入，并将节点列表发送给datanode，datanode进行流水复制
4. 最后一个datanode写入成功会返回一个`ack`，并向前传递直到客户端。客户端维护一个确认队列来检测数据块是否写入完毕。
5. 传出过程中当某个节点出现故障，首先会关闭管线，将确认队列中的数据块重新添回数据队列，为当前数据块重新注册，删除故障datanode，重新创建管线继续写入
6. 写入完成关闭数据流

#### 新特性

*版本2.0*

- HDFS HA：解决名称节点单点问题，设置多个名称节点，其中一个处于'活跃'状态，其他处于'待命'状态，'活跃'状态的名称节点处理所有请求，名称节点出现故障则由'待命'状态的节点提供服务，即'热备份'。并实时同步元数据。
- HDFS 联邦：解决命名空间唯一、无法扩张。HDFS 联邦是多台独立的名称节点，具有不同命名空间。但是整体具有一个共享的全局挂载表，即将不同的部分分别挂载在不同的名称节点上。所有名称节点存储数据依然是所有数据节点，元数据中会记录块位置。
- YARN：解决MapReduce资源调度JobTracker的单点问题、资源划分不灵活、资源消耗问题。YARN将任务调度、资源管理分开，`ResourceManager`负责全局资源管理，`ApplicationMaster`负责监控Slave的`NodeManager`进行任务调度。YARN工作在HDFS上不与上层框架绑定。